{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.datasets import fetch_datasets\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "wine_quality_import = fetch_datasets()['wine_quality']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wine_quality = pd.DataFrame(wine_quality_import.data)\n",
    "\n",
    "wine_quality['target'] = wine_quality_import.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "wine_quality.loc[wine_quality['target'] == -1, 'target'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(wine_quality.drop('target',axis=1), wine_quality['target'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "\n",
    "num_pipe = SimpleImputer(strategy=\"mean\", add_indicator=True)\n",
    "cat_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1),\n",
    ")\n",
    "\n",
    "preprocessor_tree = make_column_transformer(\n",
    "    (num_pipe, selector(dtype_include=\"number\")),\n",
    "    (cat_pipe, selector(dtype_include=\"category\")),\n",
    "    n_jobs=2,\n",
    ")\n",
    "\n",
    "rf_clf = make_pipeline(\n",
    "    preprocessor_tree, RandomForestClassifier()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [250, 261, 272, 283, 294, 305, 316, 327, 338, 350], 'max_features': ['log2', 'sqrt'], 'max_depth': [30, 35, 40, 45, 50, None], 'min_samples_leaf': [1, 2, 3, 4, 5], 'bootstrap': [True, False], 'criterion': ['gini', 'entropy']}\n"
     ]
    }
   ],
   "source": [
    "## RANDOM PARAMETER GRID SEARCH\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 250, stop = 350, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['log2','sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(30, 50, num = 5)]\n",
    "max_depth.append(None)\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2,3,4,5]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1,2,3,4,5]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_leaf':min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "                'criterion':criterion}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_random = GridSearchCV(estimator = RandomForestClassifier(), \n",
    "                               param_grid = random_grid,\n",
    "                               scoring='roc_auc',\n",
    "                               cv = 3, \n",
    "                               verbose=2, \n",
    "                               n_jobs = -1,\n",
    "                               return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1920 candidates, totalling 5760 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "             param_grid={'bootstrap': [True, False],\n",
       "                         'max_depth': [30, 35, 40, 45, 50, None],\n",
       "                         'max_features': ['auto'],\n",
       "                         'min_samples_leaf': [1, 6, 11, 16],\n",
       "                         'min_samples_split': [2, 5, 8, 12],\n",
       "                         'n_estimators': [250, 261, 272, 283, 294, 305, 316,\n",
       "                                          327, 338, 350]},\n",
       "             return_train_score=True, scoring='roc_auc', verbose=2)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8956388086414308"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 45,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 327}"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "brf_random = GridSearchCV(estimator = BalancedRandomForestClassifier(), \n",
    "                               param_grid = random_grid,\n",
    "                               scoring='roc_auc',\n",
    "                               cv = 3, \n",
    "                               verbose=2, \n",
    "                               n_jobs = -1,\n",
    "                               return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "brf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "brf_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "brf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BALANCED BAGGING\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 150, stop = 300, num = 5)]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "bb_random_grid = {'n_estimators': n_estimators,\n",
    "                 'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bb_random = GridSearchCV(estimator = BalancedBaggingClassifier(base_estimator=HistGradientBoostingClassifier(random_state=42)), \n",
    "                               param_grid = bb_random_grid,\n",
    "                               scoring='roc_auc',\n",
    "                               cv = 3, \n",
    "                               verbose=2, \n",
    "                               n_jobs = -1,\n",
    "                               return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8569596662369879"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_random.fit(X_train, y_train)\n",
    "bb_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 207, 'bootstrap': True}"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest with oversampling using SMOTE and undersampling using RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# summarize class distribution - highly imbalanced dataset\n",
    "counter = Counter(y_train)\n",
    "print(counter)\n",
    "\n",
    "\n",
    "## RANDOM PARAMETER GRID SEARCH\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [260]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [90]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "over_n = [float(x) for x in np.arange(0.1, 0.35, 0.05)]\n",
    "# RandomUnderSampler undersampling\n",
    "under_n = [float(x) for x in np.arange(0.35, 0.5, 0.05)]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "               'randomforestclassifier__max_features': max_features,\n",
    "               'randomforestclassifier__max_depth': max_depth,\n",
    "               'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "               'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "               'randomforestclassifier__bootstrap': bootstrap,\n",
    "              'smote__sampling_strategy':over_n,\n",
    "              'randomundersampler__sampling_strategy':under_n}\n",
    "\n",
    "print(random_grid)\n",
    "\n",
    "\n",
    "# define pipeline\n",
    "# oversample positive (minority) to be x% the number of negative (majority)\n",
    "over = SMOTE(sampling_strategy = 0.1)\n",
    "# randomly undersample negative (majority) to reduce the number of negative to x% of the positive (minority)\n",
    "under = RandomUnderSampler(sampling_strategy = 0.25) \n",
    "\n",
    "#steps = [('o', over), ('u', under), ('model', RandomForestClassifier())]\n",
    "#pipeline = Pipeline(steps=steps)\n",
    "\n",
    "pipeline = make_pipeline(over, under, RandomForestClassifier(n_estimators = 260,\n",
    " min_samples_split =2,\n",
    " min_samples_leaf=1,\n",
    " max_features= 'auto',\n",
    " max_depth= 90,\n",
    " bootstrap= False))\n",
    "\n",
    "rf_sampling_random = GridSearchCV(pipeline,\n",
    "                               param_grid = random_grid,\n",
    "                               scoring='roc_auc',\n",
    "                               cv = 3, verbose=2, \n",
    "                               n_jobs = -1,\n",
    "                               return_train_score = True)\n",
    "\n",
    "\n",
    "\n",
    "cvasd = cross_validate(pipeline,X_train, y_train, cv=5)\n",
    "\n",
    "rf_sampling_random.fit(X_train,y_train)\n",
    "rf_sampling_random.best_score_\n",
    "\n",
    "rf_sampling_random.best_params_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=2,\n",
       "                                   transformers=[('pipeline-1',\n",
       "                                                  Pipeline(steps=[('standardscaler',\n",
       "                                                                   StandardScaler()),\n",
       "                                                                  ('simpleimputer',\n",
       "                                                                   SimpleImputer(add_indicator=True))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x000001B78E858C08>),\n",
       "                                                 ('pipeline-2',\n",
       "                                                  Pipeline(steps=[('simpleimputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('onehotencoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x000001B78E8583C8>)])),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(class_weight='balanced', max_iter=1000))])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "\n",
    "num_pipe = make_pipeline(\n",
    "    StandardScaler(), SimpleImputer(strategy=\"mean\", add_indicator=True)\n",
    ")\n",
    "cat_pipe = make_pipeline(\n",
    "    SimpleImputer(strategy=\"constant\", fill_value=\"missing\"),\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"),\n",
    ")\n",
    "\n",
    "preprocessor_linear = make_column_transformer(\n",
    "    (num_pipe, selector(dtype_include=\"number\")),\n",
    "    (cat_pipe, selector(dtype_include=\"category\")),\n",
    "    n_jobs=2,\n",
    ")\n",
    "\n",
    "lr_clf = make_pipeline(preprocessor_linear, LogisticRegression(max_iter=1000))\n",
    "lr_clf.set_params(logisticregression__class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_result = cross_validate(lr_clf, X_train, y_train, scoring=\"roc_auc\", cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7959038021320113"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Support Vector Classification with RandomOverSampling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline, make_pipeline \n",
    "\n",
    "num_pipe = make_pipeline(\n",
    "    MinMaxScaler(feature_range=(0, 1))\n",
    ")\n",
    "cat_pipe = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"),\n",
    ")\n",
    "\n",
    "preprocessor_svc = make_column_transformer(\n",
    "    (num_pipe, selector(dtype_include=\"number\")),\n",
    "    (cat_pipe, selector(dtype_include=\"category\")),\n",
    "    n_jobs=2,\n",
    ")\n",
    "\n",
    "smote = SMOTE(sampling_strategy=0.1)\n",
    "\n",
    "rus = RandomUnderSampler(sampling_strategy=0.2)\n",
    "\n",
    "svc_clf = make_pipeline(preprocessor_svc, smote, rus, SVC(kernel='rbf',C=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result = cross_validate(svc_clf, X_train, y_train, scoring=\"roc_auc\", cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8431015172536567"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'smote__sampling_strategy':[0.1,0.2,0.3,0.4],\n",
    "              'rus__sampling_strategy':[0.1,0.2,0.3,0.4,0.5],\n",
    "              'svc__kernel':('linear', 'rbf', 'poly'), \n",
    "              'svc__C':[1,3,5,10], \n",
    "              'svc__class_weight':['balanced', None],\n",
    "              'svc__degree':[1,2]}\n",
    "\n",
    "svc_grid = GridSearchCV(svc_clf, parameters, scoring=\"roc_auc\", cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\bened\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "1080 fits failed out of a total of 3600.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1080 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\users\\bened\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\users\\bened\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\imblearn\\pipeline.py\", line 268, in fit\n",
      "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"c:\\users\\bened\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\imblearn\\pipeline.py\", line 232, in _fit\n",
      "    **fit_params_steps[name],\n",
      "  File \"c:\\users\\bened\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\users\\bened\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\imblearn\\pipeline.py\", line 394, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n",
      "  File \"c:\\users\\bened\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\imblearn\\base.py\", line 80, in fit_resample\n",
      "    self.sampling_strategy, y, self._sampling_type\n",
      "  File \"c:\\users\\bened\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\imblearn\\utils\\_validation.py\", line 534, in check_sampling_strategy\n",
      "    _sampling_strategy_float(sampling_strategy, y, sampling_type).items()\n",
      "  File \"c:\\users\\bened\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\imblearn\\utils\\_validation.py\", line 394, in _sampling_strategy_float\n",
      "    \"The specified ratio required to generate new \"\n",
      "ValueError: The specified ratio required to generate new sample in the majority class while trying to remove samples. Please increase the ratio.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\users\\bened\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\sklearn\\model_selection\\_search.py:972: UserWarning: One or more of the test scores are non-finite: [0.78508933 0.83950993 0.78084269 ... 0.78983989 0.74438845 0.7937672 ]\n",
      "  category=UserWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8577614378850189"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_grid.fit(X_train, y_train)\n",
    "svc_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rus__sampling_strategy': 0.2,\n",
       " 'smote__sampling_strategy': 0.1,\n",
       " 'svc__C': 1,\n",
       " 'svc__class_weight': None,\n",
       " 'svc__degree': 2,\n",
       " 'svc__kernel': 'rbf'}"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
