{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G:\\My Drive\\GRAD-C24_Machine_Learning\\data\n"
     ]
    }
   ],
   "source": [
    "cd \"G:\\My Drive\\GRAD-C24_Machine_Learning\\data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 52118 entries, 0 to 107727\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   year           52118 non-null  int64  \n",
      " 1   month          52118 non-null  int64  \n",
      " 2   weekday        52118 non-null  int64  \n",
      " 3   hour           52118 non-null  int64  \n",
      " 4   segment_id     52118 non-null  float64\n",
      " 5   prec_duration  52118 non-null  float64\n",
      " 6   prec_height    52118 non-null  float64\n",
      "dtypes: float64(3), int64(4)\n",
      "memory usage: 3.2 MB\n"
     ]
    }
   ],
   "source": [
    "# Negative Sample\n",
    "neg_sample_visibility = pd.read_csv('../data/processed/neg_sample_visibility.csv', index_col=[0])\n",
    "neg_sample_temperature = pd.read_csv('../data/processed/neg_sample_temperature.csv', index_col=[0])\n",
    "neg_sample_precipitation = pd.read_csv('../data/processed/neg_sample_precipitation.csv', index_col=[0])\n",
    "negative_sample = pd.read_csv('../data/processed/negative_sample.csv', index_col=[0])\n",
    "\n",
    "# Positive sample\n",
    "pos_sample_visibility = pd.read_csv('../data/processed/pos_sample_visibility.csv', index_col=[0])\n",
    "pos_sample_temperature = pd.read_csv('../data/processed/pos_sample_temperature.csv', index_col=[0])\n",
    "pos_sample_precipitation = pd.read_csv('../data/processed/pos_sample_precipitation.csv', index_col=[0])\n",
    "positive_sample = pd.read_csv('../data/processed/positive_sample.csv', index_col=[0])\n",
    "pos_sample_precipitation.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\AppData\\Local\\Temp/ipykernel_73264/605013631.py:5: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  full_data = negative_sample.append(positive_sample)\n"
     ]
    }
   ],
   "source": [
    "# Merge (we need to reset index of precipitation df)\n",
    "negative_sample['humidity'], negative_sample['temparature'], negative_sample['visibility'],negative_sample['prec_height'],negative_sample['prec_duration']  =  neg_sample_temperature['humidity'], neg_sample_temperature['temperature'], neg_sample_visibility['visibility'],neg_sample_precipitation.reset_index()['prec_height'],neg_sample_precipitation.reset_index()['prec_duration'] \n",
    "positive_sample['humidity'], positive_sample['temparature'], positive_sample['visibility'],positive_sample['prec_height'],positive_sample['prec_duration']  =  pos_sample_temperature['humidity'], pos_sample_temperature['temperature'], pos_sample_visibility['visibility'],pos_sample_precipitation.reset_index()['prec_height'],pos_sample_precipitation.reset_index()['prec_duration'] \n",
    "\n",
    "full_data = negative_sample.append(positive_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUll DATA\n",
    "full_data = full_data[[\n",
    "    'segment_id',\n",
    "    'year',\n",
    "    'month_cos',\n",
    "    'month_sin',\n",
    "    'weekday',\n",
    "    'hour_cos',\n",
    "    'hour_sin',\n",
    "    'collision_cnt',\n",
    "    'side_strt',\n",
    "    'sun_elevation_angle',\n",
    "    'humidity',\n",
    "    'temparature',\n",
    "    'visibility',\n",
    "    'prec_height',\n",
    "    'prec_duration',\n",
    "    'collision'\n",
    "]]\n",
    "\n",
    "full_data['collision_cnt'] = full_data['collision_cnt'].fillna(0)\n",
    "\n",
    "full_data = full_data.round(3)\n",
    "\n",
    "#full_data['weekday'] = full_data['weekday'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data = full_data.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 312820 entries, 0 to 52117\n",
      "Data columns (total 16 columns):\n",
      " #   Column               Non-Null Count   Dtype  \n",
      "---  ------               --------------   -----  \n",
      " 0   segment_id           312820 non-null  float64\n",
      " 1   year                 312820 non-null  int64  \n",
      " 2   month_cos            312820 non-null  float64\n",
      " 3   month_sin            312820 non-null  float64\n",
      " 4   weekday              312820 non-null  int64  \n",
      " 5   hour_cos             312820 non-null  float64\n",
      " 6   hour_sin             312820 non-null  float64\n",
      " 7   collision_cnt        312820 non-null  float64\n",
      " 8   side_strt            312820 non-null  float64\n",
      " 9   sun_elevation_angle  312820 non-null  float64\n",
      " 10  humidity             312820 non-null  float64\n",
      " 11  temparature          312820 non-null  float64\n",
      " 12  visibility           312820 non-null  float64\n",
      " 13  prec_height          312820 non-null  float64\n",
      " 14  prec_duration        312820 non-null  float64\n",
      " 15  collision            312820 non-null  int64  \n",
      "dtypes: float64(13), int64(3)\n",
      "memory usage: 40.6 MB\n"
     ]
    }
   ],
   "source": [
    "full_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_id</th>\n",
       "      <th>year</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>collision_cnt</th>\n",
       "      <th>side_strt</th>\n",
       "      <th>sun_elevation_angle</th>\n",
       "      <th>humidity</th>\n",
       "      <th>temparature</th>\n",
       "      <th>visibility</th>\n",
       "      <th>prec_height</th>\n",
       "      <th>prec_duration</th>\n",
       "      <th>collision</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42796.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.866</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-53.638</td>\n",
       "      <td>86.187</td>\n",
       "      <td>4.081</td>\n",
       "      <td>20049.462</td>\n",
       "      <td>0.009</td>\n",
       "      <td>2.242</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34322.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.866</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-36.877</td>\n",
       "      <td>88.226</td>\n",
       "      <td>3.458</td>\n",
       "      <td>23919.355</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29497.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.776</td>\n",
       "      <td>0.631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.339</td>\n",
       "      <td>55.533</td>\n",
       "      <td>20.693</td>\n",
       "      <td>34946.667</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.431</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>39002.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.920</td>\n",
       "      <td>76.000</td>\n",
       "      <td>14.227</td>\n",
       "      <td>36333.333</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32881.0</td>\n",
       "      <td>2019</td>\n",
       "      <td>-0.866</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-14.045</td>\n",
       "      <td>72.806</td>\n",
       "      <td>17.171</td>\n",
       "      <td>40709.677</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52113</th>\n",
       "      <td>21737.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.991</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.374</td>\n",
       "      <td>77.194</td>\n",
       "      <td>5.045</td>\n",
       "      <td>24145.161</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.538</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52114</th>\n",
       "      <td>2782.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.068</td>\n",
       "      <td>-0.998</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.363</td>\n",
       "      <td>82.355</td>\n",
       "      <td>4.119</td>\n",
       "      <td>24951.613</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.871</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52115</th>\n",
       "      <td>2781.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.917</td>\n",
       "      <td>0.398</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.907</td>\n",
       "      <td>81.161</td>\n",
       "      <td>3.971</td>\n",
       "      <td>22723.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52116</th>\n",
       "      <td>19720.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.577</td>\n",
       "      <td>-0.817</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.171</td>\n",
       "      <td>79.516</td>\n",
       "      <td>4.648</td>\n",
       "      <td>22467.742</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.962</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52117</th>\n",
       "      <td>2781.0</td>\n",
       "      <td>2020</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>-0.776</td>\n",
       "      <td>0.631</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.882</td>\n",
       "      <td>84.484</td>\n",
       "      <td>3.287</td>\n",
       "      <td>20290.323</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.473</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312820 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       segment_id  year  month_cos  month_sin  weekday  hour_cos  hour_sin  \\\n",
       "0         42796.0  2019      0.866       -0.5        6     0.963     0.270   \n",
       "1         34322.0  2020      0.866        0.5        6     0.460     0.888   \n",
       "2         29497.0  2018     -1.000        0.0        2    -0.776     0.631   \n",
       "3         39002.0  2020     -0.000       -1.0        6    -0.335     0.942   \n",
       "4         32881.0  2019     -0.866       -0.5        2     1.000     0.000   \n",
       "...           ...   ...        ...        ...      ...       ...       ...   \n",
       "52113     21737.0  2020      1.000       -0.0        6    -0.991    -0.136   \n",
       "52114      2782.0  2020      1.000       -0.0        2    -0.068    -0.998   \n",
       "52115      2781.0  2020      1.000       -0.0        5    -0.917     0.398   \n",
       "52116     19720.0  2020      1.000       -0.0        3    -0.577    -0.817   \n",
       "52117      2781.0  2020      1.000       -0.0        4    -0.776     0.631   \n",
       "\n",
       "       collision_cnt  side_strt  sun_elevation_angle  humidity  temparature  \\\n",
       "0                0.0        1.0              -53.638    86.187        4.081   \n",
       "1                0.0        1.0              -36.877    88.226        3.458   \n",
       "2                1.0        1.0               35.339    55.533       20.693   \n",
       "3                0.0        1.0                1.920    76.000       14.227   \n",
       "4                0.0        1.0              -14.045    72.806       17.171   \n",
       "...              ...        ...                  ...       ...          ...   \n",
       "52113            6.0        0.0               14.374    77.194        5.045   \n",
       "52114           20.0        0.0               -9.363    82.355        4.119   \n",
       "52115           21.0        0.0                9.907    81.161        3.971   \n",
       "52116           14.0        0.0                5.171    79.516        4.648   \n",
       "52117           21.0        0.0                4.882    84.484        3.287   \n",
       "\n",
       "       visibility  prec_height  prec_duration  collision  \n",
       "0       20049.462        0.009          2.242          0  \n",
       "1       23919.355        0.003          0.876          0  \n",
       "2       34946.667        0.002          0.431          0  \n",
       "3       36333.333        0.006          0.911          0  \n",
       "4       40709.677        0.001          0.113          0  \n",
       "...           ...          ...            ...        ...  \n",
       "52113   24145.161        0.002          0.538          1  \n",
       "52114   24951.613        0.004          0.871          1  \n",
       "52115   22723.333        0.000          0.409          1  \n",
       "52116   22467.742        0.004          0.962          1  \n",
       "52117   20290.323        0.000          0.473          1  \n",
       "\n",
       "[312820 rows x 16 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data[full_data.select_dtypes(np.float64).columns] = full_data.select_dtypes(np.float64).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split\n",
    "X_train = full_data[full_data['year'] < 2020].drop(['collision','segment_id'],axis=1)\n",
    "X_test = full_data[full_data['year'] == 2020].drop(['collision','segment_id'],axis=1)\n",
    "\n",
    "y_train = full_data[full_data['year'] < 2020]['collision']\n",
    "y_test = full_data[full_data['year'] == 2020]['collision']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month_cos</th>\n",
       "      <th>month_sin</th>\n",
       "      <th>weekday</th>\n",
       "      <th>hour_cos</th>\n",
       "      <th>hour_sin</th>\n",
       "      <th>collision_cnt</th>\n",
       "      <th>side_strt</th>\n",
       "      <th>sun_elevation_angle</th>\n",
       "      <th>humidity</th>\n",
       "      <th>temparature</th>\n",
       "      <th>visibility</th>\n",
       "      <th>prec_height</th>\n",
       "      <th>prec_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>0.866</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>6</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.270</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-53.638000</td>\n",
       "      <td>86.186996</td>\n",
       "      <td>4.081000</td>\n",
       "      <td>20049.462891</td>\n",
       "      <td>0.009</td>\n",
       "      <td>2.242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.776</td>\n",
       "      <td>0.631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.339001</td>\n",
       "      <td>55.533001</td>\n",
       "      <td>20.693001</td>\n",
       "      <td>34946.667969</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>-0.866</td>\n",
       "      <td>-0.500</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-14.045000</td>\n",
       "      <td>72.806000</td>\n",
       "      <td>17.171000</td>\n",
       "      <td>40709.675781</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>-1.000</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.335</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.486000</td>\n",
       "      <td>78.138000</td>\n",
       "      <td>13.845000</td>\n",
       "      <td>33616.667969</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.866</td>\n",
       "      <td>6</td>\n",
       "      <td>0.203</td>\n",
       "      <td>-0.979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-6.555000</td>\n",
       "      <td>71.392998</td>\n",
       "      <td>5.211000</td>\n",
       "      <td>28757.142578</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51890</th>\n",
       "      <td>2019</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.854</td>\n",
       "      <td>-0.520</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-44.736000</td>\n",
       "      <td>84.968002</td>\n",
       "      <td>4.529000</td>\n",
       "      <td>29403.226562</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51891</th>\n",
       "      <td>2019</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-0.888</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-26.948000</td>\n",
       "      <td>84.258003</td>\n",
       "      <td>4.897000</td>\n",
       "      <td>29974.193359</td>\n",
       "      <td>0.013</td>\n",
       "      <td>1.301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51892</th>\n",
       "      <td>2019</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.203</td>\n",
       "      <td>-0.979</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-17.841999</td>\n",
       "      <td>83.065002</td>\n",
       "      <td>5.171000</td>\n",
       "      <td>29419.355469</td>\n",
       "      <td>0.011</td>\n",
       "      <td>1.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51893</th>\n",
       "      <td>2019</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>4</td>\n",
       "      <td>0.460</td>\n",
       "      <td>-0.888</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-26.868000</td>\n",
       "      <td>84.258003</td>\n",
       "      <td>4.897000</td>\n",
       "      <td>29974.193359</td>\n",
       "      <td>0.013</td>\n",
       "      <td>1.301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51894</th>\n",
       "      <td>2019</td>\n",
       "      <td>1.000</td>\n",
       "      <td>-0.000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.683</td>\n",
       "      <td>-0.731</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-36.001999</td>\n",
       "      <td>84.484001</td>\n",
       "      <td>4.735000</td>\n",
       "      <td>30064.515625</td>\n",
       "      <td>0.005</td>\n",
       "      <td>0.887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210346 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  month_cos  month_sin  weekday  hour_cos  hour_sin  collision_cnt  \\\n",
       "0      2019      0.866     -0.500        6     0.963     0.270            0.0   \n",
       "2      2018     -1.000      0.000        2    -0.776     0.631            1.0   \n",
       "4      2019     -0.866     -0.500        2     1.000     0.000            0.0   \n",
       "5      2019     -0.000     -1.000        5    -0.335     0.942            0.0   \n",
       "6      2019      0.500      0.866        6     0.203    -0.979            0.0   \n",
       "...     ...        ...        ...      ...       ...       ...            ...   \n",
       "51890  2019      1.000     -0.000        1     0.854    -0.520           17.0   \n",
       "51891  2019      1.000     -0.000        1     0.460    -0.888           12.0   \n",
       "51892  2019      1.000     -0.000        5     0.203    -0.979            5.0   \n",
       "51893  2019      1.000     -0.000        4     0.460    -0.888           16.0   \n",
       "51894  2019      1.000     -0.000        1     0.683    -0.731           13.0   \n",
       "\n",
       "       side_strt  sun_elevation_angle   humidity  temparature    visibility  \\\n",
       "0            1.0           -53.638000  86.186996     4.081000  20049.462891   \n",
       "2            1.0            35.339001  55.533001    20.693001  34946.667969   \n",
       "4            1.0           -14.045000  72.806000    17.171000  40709.675781   \n",
       "5            0.0             2.486000  78.138000    13.845000  33616.667969   \n",
       "6            1.0            -6.555000  71.392998     5.211000  28757.142578   \n",
       "...          ...                  ...        ...          ...           ...   \n",
       "51890        0.0           -44.736000  84.968002     4.529000  29403.226562   \n",
       "51891        0.0           -26.948000  84.258003     4.897000  29974.193359   \n",
       "51892        0.0           -17.841999  83.065002     5.171000  29419.355469   \n",
       "51893        0.0           -26.868000  84.258003     4.897000  29974.193359   \n",
       "51894        0.0           -36.001999  84.484001     4.735000  30064.515625   \n",
       "\n",
       "       prec_height  prec_duration  \n",
       "0            0.009          2.242  \n",
       "2            0.002          0.431  \n",
       "4            0.001          0.113  \n",
       "5            0.005          0.928  \n",
       "6            0.004          0.708  \n",
       "...            ...            ...  \n",
       "51890        0.003          0.742  \n",
       "51891        0.013          1.301  \n",
       "51892        0.011          1.145  \n",
       "51893        0.013          1.301  \n",
       "51894        0.005          0.887  \n",
       "\n",
       "[210346 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.experimental import enable_halving_search_cv  # noqa\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "num_pipe = SimpleImputer(strategy=\"mean\", add_indicator=True)\n",
    "cat_pipe = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"),\n",
    ")\n",
    "\n",
    "preprocessor_tree = make_column_transformer(\n",
    "    (num_pipe, selector(dtype_include=\"number\")),\n",
    "    (cat_pipe, selector(dtype_include=\"category\")),\n",
    "    n_jobs=2,\n",
    ")\n",
    "\n",
    "rf_clf = make_pipeline(\n",
    "    preprocessor_tree, RandomForestClassifier(\n",
    "        n_estimators=70\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result = cross_validate(rf_clf, X_train, y_train, scoring=\"roc_auc\", cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8516781505504607"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00526757, 0.00644692, 0.00677047, 0.08422032, 0.02304137,\n",
       "       0.02113685, 0.40076729, 0.0524116 , 0.24642482, 0.04459693,\n",
       "       0.03930573, 0.01894708, 0.02373604, 0.02692701])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.fit(X_train, y_train).steps[1][1].feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mean decrease in impurity')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Feature Importance for baseline RF model\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "forest_importances = pd.Series(rf_clf.steps[1][1].feature_importances_, index=rf_clf.feature_names_in_)\n",
    "\n",
    "start_time = time.time()\n",
    "importances = rf_clf.steps[1][1].feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf_clf.steps[1][1].estimators_], axis=0)\n",
    "elapsed_time = time.time() - start_time\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "forest_importances.sort_values(axis=0, ascending=False).plot.bar(yerr=std, ax=ax)\n",
    "ax.set_title(\"Feature importances using MDI\")\n",
    "ax.set_ylabel(\"Mean decrease in impurity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': [200, 250, 300, 350, 400, 450, 500], 'max_features': ['log2', 'sqrt'], 'max_depth': [30, 40, 50, None], 'min_samples_split': [2], 'min_samples_leaf': [1], 'bootstrap': [False], 'criterion': ['entropy']}\n"
     ]
    }
   ],
   "source": [
    "## RANDOM PARAMETER GRID SEARCH\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.arange(200, 501, 50)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['log2','sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.arange(30, 51, 10)]\n",
    "max_depth.append(None)\n",
    "\n",
    "criterion = ['entropy']\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split':min_samples_split,\n",
    "               'min_samples_leaf':min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "                'criterion':criterion}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_random = RandomizedSearchCV(estimator = RandomForestClassifier(), \n",
    "                               param_distributions = random_grid,\n",
    "                               scoring='roc_auc',\n",
    "                               n_iter = 20, \n",
    "                               cv = 5,\n",
    "                               verbose=2, \n",
    "                               random_state=42, \n",
    "                               n_jobs = -1,\n",
    "                               return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=RandomForestClassifier(), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [False],\n",
       "                                        'criterion': ['entropy'],\n",
       "                                        'max_depth': [30, 40, 50, None],\n",
       "                                        'max_features': ['log2', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1],\n",
       "                                        'min_samples_split': [2],\n",
       "                                        'n_estimators': [200, 250, 300, 350,\n",
       "                                                         400, 450, 500]},\n",
       "                   random_state=42, return_train_score=True, scoring='roc_auc',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8502921198762226"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 450,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': 30,\n",
       " 'criterion': 'entropy',\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "brf_random = RandomizedSearchCV(estimator = BalancedRandomForestClassifier(), \n",
    "                               param_distributions = random_grid,\n",
    "                               scoring='roc_auc',\n",
    "                               n_iter = 20, \n",
    "                               cv = 5,\n",
    "                               verbose=2, \n",
    "                               random_state=42, \n",
    "                               n_jobs = -1,\n",
    "                               return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, estimator=BalancedRandomForestClassifier(), n_iter=20,\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [False],\n",
       "                                        'criterion': ['entropy'],\n",
       "                                        'max_depth': [30, 40, 50, None],\n",
       "                                        'max_features': ['log2', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1],\n",
       "                                        'min_samples_split': [2],\n",
       "                                        'n_estimators': [200, 250, 300, 350,\n",
       "                                                         400, 450, 500]},\n",
       "                   random_state=42, return_train_score=True, scoring='roc_auc',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8850452537225573"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brf_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 500,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'log2',\n",
       " 'max_depth': 30,\n",
       " 'criterion': 'entropy',\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 174119, 1: 36227})\n",
      "{'randomforestclassifier__n_estimators': [200, 250, 300, 350, 400, 450, 500], 'randomforestclassifier__max_features': ['log2', 'sqrt'], 'randomforestclassifier__max_depth': [30, 40, 50, None], 'randomforestclassifier__min_samples_split': [2], 'randomforestclassifier__min_samples_leaf': [1], 'randomforestclassifier__bootstrap': [False], 'randomforestclassifier__criterion': ['entropy'], 'smote__sampling_strategy': [0.25, 0.3, 0.35], 'randomundersampler__sampling_strategy': [0.4, 0.45, 0.5]}\n"
     ]
    }
   ],
   "source": [
    "#Random Forest with oversampling using SMOTE and undersampling using RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "# summarize class distribution - highly imbalanced dataset\n",
    "counter = Counter(y_train)\n",
    "print(counter)\n",
    "\n",
    "\n",
    "## RANDOM PARAMETER GRID SEARCH\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "over_n = [float(x) for x in np.arange(0.25, 0.351, 0.05)]\n",
    "#over_n = 0.1\n",
    "\n",
    "# RandomUnderSampler undersampling\n",
    "under_n = [float(x) for x in np.arange(0.4, 0.51, 0.05)]\n",
    "#under_n = 0.3\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "               'randomforestclassifier__max_features': max_features,\n",
    "               'randomforestclassifier__max_depth': max_depth,\n",
    "               'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "               'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "               'randomforestclassifier__bootstrap': bootstrap,\n",
    "               'randomforestclassifier__criterion':criterion,\n",
    "              'smote__sampling_strategy': over_n,\n",
    "              'randomundersampler__sampling_strategy': under_n}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline\n",
    "# oversample positive (minority) to be x% the number of negative (majority)\n",
    "over = SMOTE()\n",
    "# randomly undersample negative (majority) to reduce the number of negative to x% of the positive (minority)\n",
    "under = RandomUnderSampler() \n",
    "\n",
    "pipeline = make_pipeline(over, under, RandomForestClassifier())\n",
    "\n",
    "rf_sampling_random = RandomizedSearchCV(pipeline, \n",
    "                               param_distributions = random_grid,\n",
    "                               scoring='roc_auc',\n",
    "                               n_iter = 20, \n",
    "                               cv = 5,\n",
    "                               verbose=2, \n",
    "                               random_state=42, \n",
    "                               n_jobs = -1,\n",
    "                               return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5,\n",
       "                   estimator=Pipeline(steps=[('smote', SMOTE()),\n",
       "                                             ('randomundersampler',\n",
       "                                              RandomUnderSampler()),\n",
       "                                             ('randomforestclassifier',\n",
       "                                              RandomForestClassifier())]),\n",
       "                   n_iter=20, n_jobs=-1,\n",
       "                   param_distributions={'randomforestclassifier__bootstrap': [False],\n",
       "                                        'randomforestclassifier__criterion': ['entropy'],\n",
       "                                        'randomforestclassifier__max_depth': [30,\n",
       "                                                                              40,\n",
       "                                                                              50,\n",
       "                                                                              None],\n",
       "                                        'randomforestclassifier__max_features': ['log2',\n",
       "                                                                                 'sqrt'],\n",
       "                                        'randomforestclassifier__min_samples_leaf': [1],\n",
       "                                        'randomforestclassifier__min_samples_split': [2],\n",
       "                                        'randomforestclassifier__n_estimators': [200,\n",
       "                                                                                 250,\n",
       "                                                                                 300,\n",
       "                                                                                 350,\n",
       "                                                                                 400,\n",
       "                                                                                 450,\n",
       "                                                                                 500],\n",
       "                                        'randomundersampler__sampling_strategy': [0.4,\n",
       "                                                                                  0.45,\n",
       "                                                                                  0.5],\n",
       "                                        'smote__sampling_strategy': [0.25, 0.3,\n",
       "                                                                     0.35]},\n",
       "                   random_state=42, return_train_score=True, scoring='roc_auc',\n",
       "                   verbose=2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_sampling_random.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8588648838645139"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_sampling_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'smote__sampling_strategy': 0.3,\n",
       " 'randomundersampler__sampling_strategy': 0.5,\n",
       " 'randomforestclassifier__n_estimators': 500,\n",
       " 'randomforestclassifier__min_samples_split': 2,\n",
       " 'randomforestclassifier__min_samples_leaf': 1,\n",
       " 'randomforestclassifier__max_features': 'sqrt',\n",
       " 'randomforestclassifier__max_depth': 30,\n",
       " 'randomforestclassifier__criterion': 'entropy',\n",
       " 'randomforestclassifier__bootstrap': False}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_sampling_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# BALANCED BAGGING\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.arange(300, 501, 100)]\n",
    "\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True]\n",
    "\n",
    "# max_features\n",
    "max_features = [0.6,1.0]\n",
    "\n",
    "#Sampling strategy\n",
    "sampling_strategy = [0.2,0.3,0.4]\n",
    "\n",
    "#sampler\n",
    "sampler = [RandomUnderSampler(),SMOTE()]\n",
    "\n",
    "\n",
    "# Create the random grid\n",
    "bb_random_grid = {'n_estimators': n_estimators,\n",
    "                 'bootstrap': bootstrap,\n",
    "                 'sampling_strategy':sampling_strategy,\n",
    "                 'sampler':sampler,\n",
    "                 'max_features':max_features}\n",
    "\n",
    "# Create the random grid\n",
    "bb_random_grid = {'n_estimators': n_estimators,\n",
    "                 'bootstrap': bootstrap,\n",
    "                 'sampling_strategy':sampling_strategy,\n",
    "                 'sampler':sampler,\n",
    "                 'max_features':max_features}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb_random = RandomizedSearchCV(estimator = BalancedBaggingClassifier(base_estimator=HistGradientBoostingClassifier(random_state=42)), \n",
    "                               param_distributions = bb_random_grid,\n",
    "                               scoring='roc_auc',\n",
    "                               n_iter=15,\n",
    "                               cv = 3, \n",
    "                               verbose=3, \n",
    "                               n_jobs = -1,\n",
    "                               return_train_score = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "15 fits failed out of a total of 45.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "12 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\imblearn\\ensemble\\_bagging.py\", line 331, in fit\n",
      "    return super().fit(X, y)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 269, in fit\n",
      "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\imblearn\\ensemble\\_bagging.py\", line 346, in _fit\n",
      "    return super()._fit(X, y, self.max_samples, sample_weight=None)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 394, in _fit\n",
      "    all_results = Parallel(\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 126, in _parallel_build_estimators\n",
      "    estimator.fit((X[indices])[:, features], y[indices])\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 268, in fit\n",
      "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 226, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 394, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\imblearn\\base.py\", line 79, in fit_resample\n",
      "    self.sampling_strategy_ = check_sampling_strategy(\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py\", line 534, in check_sampling_strategy\n",
      "    _sampling_strategy_float(sampling_strategy, y, sampling_type).items()\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py\", line 393, in _sampling_strategy_float\n",
      "    raise ValueError(\n",
      "ValueError: The specified ratio required to generate new sample in the majority class while trying to remove samples. Please increase the ratio.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\imblearn\\ensemble\\_bagging.py\", line 331, in fit\n",
      "    return super().fit(X, y)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 269, in fit\n",
      "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\imblearn\\ensemble\\_bagging.py\", line 346, in _fit\n",
      "    return super()._fit(X, y, self.max_samples, sample_weight=None)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 394, in _fit\n",
      "    all_results = Parallel(\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_bagging.py\", line 126, in _parallel_build_estimators\n",
      "    estimator.fit((X[indices])[:, features], y[indices])\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 268, in fit\n",
      "    Xt, yt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 226, in _fit\n",
      "    X, y, fitted_transformer = fit_resample_one_cached(\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\", line 394, in _fit_resample_one\n",
      "    X_res, y_res = sampler.fit_resample(X, y, **fit_params)\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\imblearn\\base.py\", line 79, in fit_resample\n",
      "    self.sampling_strategy_ = check_sampling_strategy(\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py\", line 534, in check_sampling_strategy\n",
      "    _sampling_strategy_float(sampling_strategy, y, sampling_type).items()\n",
      "  File \"C:\\Users\\admin\\anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py\", line 373, in _sampling_strategy_float\n",
      "    raise ValueError(\n",
      "ValueError: The specified ratio required to remove samples from the minority class while trying to generate new samples. Please increase the ratio.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.90516476        nan 0.90512662        nan 0.8992422\n",
      " 0.90512457 0.89876815 0.90508951        nan 0.89935937 0.89887038\n",
      " 0.90545202 0.89851886        nan]\n",
      "  warnings.warn(\n",
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the train scores are non-finite: [       nan 0.95674841        nan 0.9567447         nan 0.95362823\n",
      " 0.95683478 0.95357009 0.95683035        nan 0.9538373  0.95344064\n",
      " 0.95660216 0.95337084        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3,\n",
       "                   estimator=BalancedBaggingClassifier(base_estimator=HistGradientBoostingClassifier(random_state=42)),\n",
       "                   n_iter=15, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True],\n",
       "                                        'max_features': [0.6, 1.0],\n",
       "                                        'n_estimators': [300, 400, 500],\n",
       "                                        'sampler': [RandomUnderSampler(),\n",
       "                                                    SMOTE()],\n",
       "                                        'sampling_strategy': [0.2, 0.3, 0.4]},\n",
       "                   return_train_score=True, scoring='roc_auc', verbose=3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9054520202614468"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sampling_strategy': 0.3,\n",
       " 'sampler': SMOTE(),\n",
       " 'n_estimators': 300,\n",
       " 'max_features': 1.0,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(n_jobs=2,\n",
       "                                   transformers=[('pipeline-1',\n",
       "                                                  Pipeline(steps=[('standardscaler',\n",
       "                                                                   StandardScaler()),\n",
       "                                                                  ('simpleimputer',\n",
       "                                                                   SimpleImputer(add_indicator=True))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x000001B43CEC5A00>),\n",
       "                                                 ('pipeline-2',\n",
       "                                                  Pipeline(steps=[('onehotencoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  <sklearn.compose._column_transformer.make_column_selector object at 0x000001B43CE95E80>)])),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(class_weight='balanced', max_iter=1000))])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LOGISTIC REGRESSION\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.compose import make_column_selector as selector\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "\n",
    "num_pipe = make_pipeline(\n",
    "    StandardScaler(), SimpleImputer(strategy=\"mean\", add_indicator=True)\n",
    ")\n",
    "cat_pipe = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"),\n",
    ")\n",
    "\n",
    "preprocessor_linear = make_column_transformer(\n",
    "    (num_pipe, selector(dtype_include=\"number\")),\n",
    "    (cat_pipe, selector(dtype_include=\"category\")),\n",
    "    n_jobs=2,\n",
    ")\n",
    "\n",
    "lr_clf = make_pipeline(preprocessor_linear, LogisticRegression(max_iter=1000))\n",
    "lr_clf.set_params(logisticregression__class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv_result = cross_validate(lr_clf, X_train, y_train, scoring=\"roc_auc\", cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8938550879498177"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Support Vector Classification with RandomOverSampling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline, make_pipeline \n",
    "\n",
    "num_pipe = make_pipeline(\n",
    "    MinMaxScaler(feature_range=(0, 1))\n",
    ")\n",
    "cat_pipe = make_pipeline(\n",
    "    OneHotEncoder(handle_unknown=\"ignore\"),\n",
    ")\n",
    "\n",
    "preprocessor_svc = make_column_transformer(\n",
    "    (num_pipe, selector(dtype_include=\"number\")),\n",
    "    (cat_pipe, selector(dtype_include=\"category\")),\n",
    "    n_jobs=2,\n",
    ")\n",
    "\n",
    "smote = SMOTE()\n",
    "\n",
    "rus = RandomUnderSampler()\n",
    "\n",
    "svc_clf = make_pipeline(preprocessor_svc, smote, rus, SVC())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21244/4223034172.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_validate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvc_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"roc_auc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;31m# independent, and that it is pickle-able.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m     results = parallel(\n\u001b[0m\u001b[0;32m    268\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    269\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    270\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"passthrough\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"i\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    313\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_probB\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_status_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlibsvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#cv_result = cross_validate(svc_clf, X_train, y_train, scoring=\"roc_auc\", cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_result['test_score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'smote__sampling_strategy':[float(x) for x in np.arange(0.30, 0.351, 0.05)],\n",
    "              'randomundersampler__sampling_strategy':[float(x) for x in np.arange(0.45, 0.51, 0.05)],\n",
    "              'svc__kernel':('linear', 'rbf', 'poly'), \n",
    "              'svc__C':[1,10,100],\n",
    "              'svc__gamma':[1,0.1,0.001], \n",
    "              'svc__degree':[1,2]}\n",
    "\n",
    "\n",
    "svc_grid = RandomizedSearchCV(svc_clf, \n",
    "                               param_distributions = parameters,\n",
    "                               scoring='roc_auc',\n",
    "                               n_iter = 10, \n",
    "                               cv = 5,\n",
    "                               verbose=2, \n",
    "                               random_state=42, \n",
    "                               n_jobs = -1,\n",
    "                               return_train_score = True)\n",
    "\n",
    "#svc_grid = GridSearchCV(svc_clf, parameters, scoring=\"roc_auc\", cv=3, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "svc_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
